{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephen-crone/monkeypox/blob/main/model_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdOh0eUFsWSh"
      },
      "source": [
        "# **<br>Detecting Misinformation and Superspreaders in Social Media:<br>Designing a System for the Next Pandemic**\n",
        "#Phase 2:  Training and evaluating candidate models\n",
        "\n",
        "Stephen Crone\n",
        "<br>\n",
        "<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnGGR0Yzvao-"
      },
      "source": [
        "---\n",
        "## **1. Setting up programming environment**\n",
        "Our first step will be to install and import the libraries we need.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IanCffMyhksH"
      },
      "source": [
        "###**1.1. Installing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yFOxOtW1sMiB"
      },
      "outputs": [],
      "source": [
        "# For access to transformer models.\n",
        "!pip install transformers\n",
        "# For operations on HuggingFace dataset objects.\n",
        "!pip install datasets\n",
        "# For few-shot learning (FSL) experiments.\n",
        "!pip install accelerate\n",
        "# For tokenization with Deberta models.\n",
        "!pip install sentencepiece\n",
        "# For additional optimizer options.\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmaJvm6fhmwq"
      },
      "source": [
        "###**1.2. Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubMBBRjv0IPN"
      },
      "outputs": [],
      "source": [
        "# For file handling and data exports.\n",
        "from google.colab import files\n",
        "from openpyxl import Workbook, load_workbook\n",
        "import os\n",
        "# For general dataset manipulation.\n",
        "from datasets import ClassLabel, Dataset, DatasetDict, Features, Value\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "# For dataset preprocessing (e.g. splitting, tokenization).\n",
        "from transformers import AutoTokenizer, DefaultDataCollator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece\n",
        "# For exploratory data analysis.\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from wordcloud import WordCloud\n",
        "# For model training.\n",
        "from transformers import TFAutoModelForSequenceClassification, pipeline, GPTJForCausalLM\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "# For model evaluation.\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# For visualisation.\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "# For model export to HuggingFace hub.\n",
        "from huggingface_hub import notebook_login\n",
        "# Other imports\n",
        "import random as python_random\n",
        "import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_GljWdVhpU-"
      },
      "source": [
        "###**1.3. Setting random seed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfpHH12PcleT"
      },
      "outputs": [],
      "source": [
        "# Setting random seed\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "python_random.seed(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "RJT78Mh3arZw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz198uQLnVqJ"
      },
      "source": [
        "---\n",
        "## **2. Importing the dataset**\n",
        "In this section, we load the monkeypox misinformation dataset and create two versions to use in the notebook: the first a full version (based on the 'misinformation' vs 'other' class split); the second a smaller subset (based on the 'misinformation' vs 'good information' class split).\n",
        "\n",
        "Please note: user must upload a Kaggle API token to session storage in order to successfully download the dataset. Failure to do so will generate an error.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sraK1NtCwt8V"
      },
      "outputs": [],
      "source": [
        "# Preparing Kaggle and Kaggle API token.\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "# Downloading the dataset from Kaggle.\n",
        "! kaggle datasets download stephencrone/monkeypox\n",
        "# Unzipping the dataset.\n",
        "! unzip monkeypox\n",
        "# Assigning dataset to Pandas DataFrame.\n",
        "bigDF = pd.read_csv('/content/monkeypox.csv')\n",
        "# Reconfiguring datetime features.\n",
        "bigDF['created_at'] = pd.to_datetime(bigDF['created_at'])\n",
        "bigDF['user created at'] = pd.to_datetime(bigDF['user created at'])\n",
        "# Creating a second, smaller DataFrame where we replace 'other' (i.e. non-misinformation)\n",
        "# class with 'good' (i.e. reliable information) class.\n",
        "littleDF = bigDF.copy()\n",
        "littleDF = littleDF.drop(littleDF[littleDF.ternary_class == 9].index)\n",
        "littleDF = littleDF.drop(['binary_class'],axis=1)\n",
        "littleDF = littleDF.rename(columns={\"ternary_class\": \"class\"})\n",
        "# Removing redundant class label column from bigDF.\n",
        "bigDF = bigDF.drop(['ternary_class'],axis=1)\n",
        "bigDF = bigDF.rename(columns={\"binary_class\": \"class\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by1ZPVt5l0q2"
      },
      "source": [
        "<br>\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx2JNqjQyR26"
      },
      "source": [
        "---\n",
        "## **3. Exploratory data analysis**\n",
        "In this section we provide an overview of the features in the dataset and their data types; consider the superficial lexical differences that can be observed between the classes; and identify the features, aside from tweet text, which might help in separating the classes.  \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUcVDu3Mmo_J"
      },
      "source": [
        "###**3.1. Overview of dataset features and class distribution**\n",
        "As the following table shows, we have a wealth of tweet-related and user-related features that we could potentially feed to our classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vh_SO8To0w-U"
      },
      "outputs": [],
      "source": [
        "bigDF.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8V1FlwYpBoN"
      },
      "source": [
        "Given that this is a dataset that we have collated ourselves, we know already that there are no missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uWqsSHN50W7"
      },
      "outputs": [],
      "source": [
        "bigDF.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMqPx5g3pLdX"
      },
      "source": [
        "We have a choice, however, of two binary labelling systems: a 'misinformation' / 'other' system involving the full dataset ('bigDF'); or a 'misinformation' / 'good information' system ('littleDF'). 'Good information' posts are a subset of the 'other' class, meaning that this dataset is the smaller of the two. However, it has the advantage of being less imbalanced in terms of the underrepresentation of the 'misinformation' class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB-6W8edEGbk"
      },
      "outputs": [],
      "source": [
        "# Show class distribution for larger version of dataset.\n",
        "bigDF['class'].value_counts(normalize=True).sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O-IegwG0S1U"
      },
      "outputs": [],
      "source": [
        "# Show class distribution for smaller version of dataset.\n",
        "littleDF['class'].value_counts(normalize=True).sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGVdz3tzu0Xh"
      },
      "source": [
        "###**3.2. Exploring the similarity of the classes**\n",
        "Although it will be for the transformer model to separate the classes, we can form a preliminary view as to how difficult this is likely to be based on some straightforward lexical analysis of the tweets themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OInacXkv-lDs"
      },
      "source": [
        "Overall, this analysis suggests that whilst there are discernible differences between the classes, separating them is not likely to be a trivial task. This view is supported firstly by our word clouds. As the word clouds show, the misinformation category clearly reflects a distinct set of themes, centred for example on the purported transmission of the virus via gay sex and airborne particles. However, there are also points of overlap between the classes -- including for example the discussion of Covid-19 in the context of both 'misinformation' and 'other' posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bZzDEi7pCWW"
      },
      "outputs": [],
      "source": [
        "# Selecting samples from each of the three classes.\n",
        "tweets_containing_misinformation = bigDF.loc[bigDF['class'] == 1]\n",
        "tweets_not_containing_misinformation = bigDF.loc[bigDF['class'] == 0]\n",
        "tweets_containing_reliable_information = littleDF.loc[littleDF['class'] == 0]\n",
        "threeViews = [[\"Tweets containing misinformation\",tweets_containing_misinformation],\n",
        "              [\"Tweets not containing misinformation\",tweets_not_containing_misinformation],\n",
        "              [\"Tweets containing reliable information\",tweets_containing_reliable_information]]\n",
        "# Creating set of stopwords to exclude from wordclouds.\n",
        "stopWords = set(stopwords.words('english'))\n",
        "stopWords = ['monkey','pox','_URL_','monkeypox','amp','get'] + list(stopWords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKcH51VjkNlA"
      },
      "outputs": [],
      "source": [
        "# # Creating and plotting trio of wordclouds.\n",
        "for i in range(len(threeViews)):\n",
        "  x = WordCloud(stopwords=stopWords,width=3500,height=2500,max_words=100,collocations=False).generate(' '.join(threeViews[i][1]['text']))\n",
        "  plt.figure( figsize=(20,10) )\n",
        "  plt.imshow(x)\n",
        "  plt.axis(\"off\")\n",
        "  print(threeViews[i][0])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3V8eA0JHUv4"
      },
      "source": [
        "Visualising the sentence embeddings produced in Section 6.4 equally suggests that the classes are not readily separable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3.3. Identifying features that might help to separate the classes**\n",
        "We have various features -- including various text features, besides tweets themselves -- that we could additionally incorporate into our transformer model. The good news, given the maximum length of a tweet and the maximum number of tokens that transformer models can typically accommodate, is that there is plenty of scope to incorporate these additional features as part of a single input pattern. Moreover, there is evidence to suggest that transformer models can understand numbers, despite the fact that they are obviously parsed by the model as token embeddings rather than numerical data per se [(Wallace et al., 2019)](https://arxiv.org/abs/1909.07940). This opens up the possibility that even numerical features could be used to enrich the model."
      ],
      "metadata": {
        "id": "TV50aGfk7tld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of features that might be helpful in separating our classes, it seems possible that **tweet source** might be of use. Although there is little difference between the 'misinformation' and 'other' classes, it is evident that the subset of reliable tweets from the 'other' class features a greater proportion of tweets published via tweet schedulers and web software (e.g. Wordpress)."
      ],
      "metadata": {
        "id": "2RZ-z3NfF4Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show tweet source in descending order of importance for misinformation class (1).\n",
        "pd.crosstab(bigDF['source'], bigDF['class'],normalize='columns').sort_values(by=1, axis=0, ascending=False, kind='stable').head(10)"
      ],
      "metadata": {
        "id": "YC0RJg4L9X6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show tweet source in descending order of importance for reliable information class (0).\n",
        "pd.crosstab(littleDF['source'], littleDF['class'],normalize='columns').sort_values(by=0, axis=0, ascending=False, kind='stable').head(10)"
      ],
      "metadata": {
        "id": "mJ62L_0TGBpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another possibly useful feature is the '**userverified**' column. As the data tables below demonstrate, although few accounts overall are verified, verified accounts are much less likely to publish misleading posts."
      ],
      "metadata": {
        "id": "O6-gxo_lKBb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the breakdown of 'user is verified values'.\n",
        "bigDF['user is verified'].value_counts(normalize=True).sort_index()"
      ],
      "metadata": {
        "id": "0msPcG-WIB1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Break down class distribution by 'user is verified' values (bigger version of dataset).\n",
        "pd.crosstab(bigDF['user is verified'], bigDF['class'],normalize='index')"
      ],
      "metadata": {
        "id": "k2myAGc0IQ5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Break down class distribution by 'user is verified' values (smaller version of dataset).\n",
        "pd.crosstab(littleDF['user is verified'], littleDF['class'],normalize='index')"
      ],
      "metadata": {
        "id": "k_xWnr4HKs8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option is whether or not the user has a **URL** listed on their profile. Only 38 per cent of posts (in the full dataset) are by users with an external URL. The data suggests that these posts are far less likely to spread misinformation (perhaps because users with URLs are more likely to be institutional users)."
      ],
      "metadata": {
        "id": "sO93DpN7Zftm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the overall breakdown of 'user has url' values.\n",
        "bigDF['user has url'].value_counts(normalize=True).sort_index()"
      ],
      "metadata": {
        "id": "RcXjaOiLZlmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a cross-tab of 'user has url' and class for the larger dataset.\n",
        "pd.crosstab(bigDF['user has url'], bigDF['class'],normalize='index')"
      ],
      "metadata": {
        "id": "dH3OyvxwZrbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a cross-tab of 'user has url' and class for the smaller dataset.\n",
        "pd.crosstab(littleDF['user has url'], littleDF['class'],normalize='index')"
      ],
      "metadata": {
        "id": "TGhEJrPMaJPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would not necessarily expect a relationship between **when the user profile was created** and their propensity for spreading misinformation. However, the fact that so many accounts have been created so recently seems suspicious. Indeed, recently created accounts seem to be especially prevalent among the misinformation class. This raises the possibility of a 'years since account creation' variable being of use in separating the classes."
      ],
      "metadata": {
        "id": "unsGKYGRgDRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots showing when accounts were created, according to class label.\n",
        "print(\"User created at (all users)\")\n",
        "sns.displot(data=bigDF,x='user created at',kind='hist',col='class',stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "I-42t8fDgC37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We cannot use post metrics to help judge which class a tweet belongs to as these features will be unavailable (or artificially low) for any tweet that is gathered in real-time (or shortly after publication).\n",
        "\n",
        "As such, we move on to consider **user metrics**. Here, we notice that users posting misinformation are likely to have a smaller footprint in general. In particular, users posting misinformation are noted as having fewer followers."
      ],
      "metadata": {
        "id": "IsvR9cSjseU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots showing the number of followers, according to class label.\n",
        "sns.displot(data=bigDF,x='followers count',kind='hist',col='class',binrange=(0,10000),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "W-wEKEB2vSq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print boxplots showing the number of followers, according to class label.\n",
        "sns.boxplot(data=bigDF, x='class',y='followers count', showfliers=False)"
      ],
      "metadata": {
        "id": "zy6wuEULEyvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots showing the number of accounts followed, according to class label.\n",
        "sns.displot(data=bigDF,x='following count',kind='hist',col='class',binrange=(0,10000),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "oZjYmmTm0qGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print boxplots showing the number of accounts followed, according to class label.\n",
        "sns.boxplot(data=bigDF, x='class',y='following count', showfliers=False)"
      ],
      "metadata": {
        "id": "48gWHO09E9X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots showing the number of tweets published, according to class label.\n",
        "sns.displot(data=bigDF,x='tweet count',kind='hist',col='class',binrange=(0,100000),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "zNLmaPQ6x-Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print boxplots showing the number of lists to which user belongs, according to class label.\n",
        "sns.displot(data=bigDF,x='listed_count',kind='hist',col='class',binrange=(0,50),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "nuS7tGBY1pt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Section 6, we will consider whether these features (or features based on them) can assist fine-tuned models."
      ],
      "metadata": {
        "id": "IgjEVf_BTnpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "KEgFzZrIaw4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **4. Zero-shot experiments**\n",
        "\n",
        "---\n",
        "Zero-shot learning can be done a number of ways [(Davison, 2020)](https://joeddav.github.io/blog/2020/05/29/ZSL.html), with the chosen paradigm having implications in terms of the appropriate model architecture and pretraining regimen. We do not have time during this project to research and experiment with all of these methods, so we opt for the commonly used natural langugage inference (NLI) method, where the text is presented as a premise and the label is treated as a hypothesis. Only models that have been pretrained on NLI tasks are appropriate for this approach to zero-shot learning (which excludes 'vanilla' BERT and other models that we might look to under a pretraining / fine-tuning approach). As such, we will conduct experiments here with two NLI trained models: 'bart-large-mlni' and 'nli-distilroberta-base'.\n",
        "\n"
      ],
      "metadata": {
        "id": "gnf9Ju-sIa0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.1. Instantiating model and tokenizer**"
      ],
      "metadata": {
        "id": "aCMpJDnkh4N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating model and tokenizer via the HuggingFace pipeline.\n",
        "zslModelChoice = 'cross-encoder/nli-distilroberta-base'\n",
        "zslClassifier = pipeline(task='zero-shot-classification', model=zslModelChoice)"
      ],
      "metadata": {
        "id": "kgC8xVYtIaiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.2. Preparing copy of the dataset**"
      ],
      "metadata": {
        "id": "5i8qmXqah9ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking dataset version to use.\n",
        "zslDatasetChoice = \"bigDF\"\n",
        "# Picking the class labels that we will experiment with.\n",
        "candidateLabels = ['Authoritative','Unauthoritative']\n",
        "# Creating a DataFrame in which to store our results.\n",
        "if zslDatasetChoice == \"littleDF\":\n",
        "  zslDF = pd.DataFrame(data={\"text\": littleDF['text'].copy(),\n",
        "                                \"class\": littleDF['class'].copy(),\n",
        "                                candidateLabels[0]:np.nan,\n",
        "                                candidateLabels[1]:np.nan,\n",
        "                                \"predictedLabel\":np.nan,\n",
        "                                  \"timeRequired\":np.nan})\n",
        "elif zslDatasetChoice == \"bigDF\":\n",
        "  zslDF = pd.DataFrame(data={\"text\": bigDF['text'].copy(),\n",
        "                                \"class\": bigDF['class'].copy(),\n",
        "                                candidateLabels[0]:np.nan,\n",
        "                                candidateLabels[1]:np.nan,\n",
        "                                \"predictedLabel\":np.nan,\n",
        "                                  \"timeRequired\":np.nan})\n",
        "else:\n",
        "  raise ValueError(\"zslDatasetChoice must be either 'bigDF' or 'littleDF'\")"
      ],
      "metadata": {
        "id": "7OULGJwWIz6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally: split dataset and use a smaller test set, given time required for each inference step.\n",
        "# Note: comment out the line below if no splitting is desired.\n",
        "zslDF, zslDiscard = train_test_split(zslDF, test_size=0.95, shuffle=True, random_state=7, stratify=zslDF['class'])"
      ],
      "metadata": {
        "id": "n9LPKEo3NcPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.3. Calling model and storing predictions**"
      ],
      "metadata": {
        "id": "F_HORndFiIQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each tweet in our dataset ...\n",
        "for i in range(len(zslDF.index)):\n",
        "  # Time each step.\n",
        "  start = time.time()\n",
        "  sequence = zslDF['text'].iloc[i]\n",
        "  # Pass the tweet to the ZSL classifier.\n",
        "  result = zslClassifier(sequence,candidateLabels)\n",
        "  # Assign the confidence scores to the correct columns of the df.\n",
        "  if result['labels'][0] == candidateLabels[0]:\n",
        "    zslDF.loc[zslDF.index[i], candidateLabels[0]] = result['scores'][0]\n",
        "    zslDF.loc[zslDF.index[i], candidateLabels[1]] = result['scores'][1]\n",
        "  else:\n",
        "    zslDF.loc[zslDF.index[i], candidateLabels[0]] = result['scores'][1]\n",
        "    zslDF.loc[zslDF.index[i], candidateLabels[1]] = result['scores'][0]\n",
        "  # Assign a predicted class label.\n",
        "  if zslDF.loc[zslDF.index[i], candidateLabels[0]] > 0.5:\n",
        "    zslDF.loc[zslDF.index[i], 'predictedLabel'] = 0\n",
        "  else:\n",
        "    zslDF.loc[zslDF.index[i], 'predictedLabel'] = 1\n",
        "  # Record time per step.\n",
        "  end = time.time()\n",
        "  zslDF.loc[zslDF.index[i], 'timeRequired'] = end-start"
      ],
      "metadata": {
        "id": "eHgi-CDSukY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.4. Analysis of results**"
      ],
      "metadata": {
        "id": "THlDWPEwiTRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recasting unwanted float values as int.\n",
        "zslDF['predictedLabel'].astype('int', copy=False, errors='raise')"
      ],
      "metadata": {
        "id": "V2ZafenyN6Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a confusion matrix based on model predictions.\n",
        "confusionMatrix = confusion_matrix(zslDF['class'], zslDF['predictedLabel'], labels=None, sample_weight=None, normalize=None)"
      ],
      "metadata": {
        "id": "32nbAAqwOABm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix.\n",
        "sns.heatmap(confusionMatrix, square=True, annot=True, cbar=False, cmap=\"Blues\",fmt='g')\n",
        "plt.title(\"Zero-shot learning performance\")\n",
        "plt.xlabel('predicted value')\n",
        "plt.ylabel('true value')\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "uHaDxVJYOD4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating classification report based on model predictions.\n",
        "classificationReport = classification_report(zslDF['class'],zslDF['predictedLabel'],digits=5)"
      ],
      "metadata": {
        "id": "I6QQYg6jOHAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing classification report.\n",
        "print(classificationReport)"
      ],
      "metadata": {
        "id": "06IJgeBSOJur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4.5. Exporting experimental data**"
      ],
      "metadata": {
        "id": "UCNpDFo1ic0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting results data to an Excel sheet.\n",
        "zslDF.to_excel('zslResults.xlsx', sheet_name='data')"
      ],
      "metadata": {
        "id": "RsxR6Es2OXGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding classification report to Excel workbook.\n",
        "classificationReportForPrint = classification_report(zslDF['class'],zslDF['predictedLabel'],digits=5,output_dict=True)\n",
        "classificationReportDF = pd.DataFrame(classificationReportForPrint).transpose()\n",
        "classificationReportExport = classificationReportDF.to_excel('classReportZSL.xlsx')\n",
        "# Loading Excel workbooks.\n",
        "wb = load_workbook(filename = 'zslResults.xlsx')\n",
        "wbCR = load_workbook(filename = 'classReportZSL.xlsx')\n",
        "# Creating new worksheet which is a copy of classification report.\n",
        "ws1 = wb.create_sheet(title=\"class. report\")\n",
        "ws2 = wbCR.active\n",
        "for row in ws2:\n",
        "    for cell in row:\n",
        "        ws1[cell.coordinate].value = cell.value\n",
        "# Saving changes.\n",
        "wb.save(filename = 'zslResults.xlsx')"
      ],
      "metadata": {
        "id": "MZj9u-nq32fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding metadata to Excel workbook.\n",
        "wb = load_workbook(filename = 'zslResults.xlsx')\n",
        "ws = wb.create_sheet(title=\"metadata\")\n",
        "ws['A1'] = \"Date\"\n",
        "ws['B1'] = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "ws['A3'] = \"Candidate labels\"\n",
        "ws['B3'] = candidateLabels[0]\n",
        "ws['C3'] = candidateLabels[1]\n",
        "ws['A5'] = \"Model used\"\n",
        "ws['B5'] = zslModelChoice\n",
        "ws['A7'] = \"Dataset used\"\n",
        "ws['B7'] = zslDatasetChoice\n",
        "# Saving changes.\n",
        "wb.save(filename = 'zslResults.xlsx')"
      ],
      "metadata": {
        "id": "WcgVE15-Om66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading results file.\n",
        "os.rename(\"zslResults.xlsx\",\"zsl-{}-{}-{}-{}.xlsx\".format(candidateLabels[0],zslDatasetChoice,datetime.datetime.now().month,datetime.datetime.now().day))\n",
        "files.download(\"zsl-{}-{}-{}-{}.xlsx\".format(candidateLabels[0],zslDatasetChoice,datetime.datetime.now().month,datetime.datetime.now().day))"
      ],
      "metadata": {
        "id": "kbZFTSZQBj_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "8fYBt5xTazDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **5. Few-shot experiments**\n",
        "\n",
        "---\n",
        "Similar to zero-shot learning (ZSL), few-shot learning (FSL) can be approached in different ways. Importantly, not every way of doing ZSL is easily adaptable to a few-shot setting, and not all models are equally adept in different settings (i.e. ZSL vs FSL). Just like our experiments with ZSL, we do not have time during this project to experiment comprehensively with different FSL approaches. Accordingly, we will trial one common way of doing FSL. This involves the use of a very large autoregressive model, which are not usually known for classification tasks, but whose text generation abilities can be used for *de facto* classification. We base our approach on one [suggested by HuggingFace](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/GPT-J-6B/Inference_with_GPT_J_6B.ipynb).\n",
        "\n",
        "Similar to our zero-shot experiments, we conduct our FSL experiments using the smaller and more easily separable version of our dataset (with the 'good' information vs 'bad' information distinction)."
      ],
      "metadata": {
        "id": "jnWYx0BF98mA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.1. Instantiating model and tokenizer**"
      ],
      "metadata": {
        "id": "4iVJ41Tvio7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating GPT-J model and tokenizer.\n",
        "fslModelChoice = 'EleutherAI/gpt-j-6B'\n",
        "tokenizer = AutoTokenizer.from_pretrained(fslModelChoice)\n",
        "fslModel = GPTJForCausalLM.from_pretrained(fslModelChoice, low_cpu_mem_usage=True, torch_dtype=torch.float32, pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "vOCunmwH-9qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.2. Preparing copy of the dataset**"
      ],
      "metadata": {
        "id": "QJTY_-QXitta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking dataset version to use.\n",
        "fslDatasetChoice = \"littleDF\"\n",
        "# Creating a DataFrame in which to store our results.\n",
        "if fslDatasetChoice == \"littleDF\":\n",
        "  fslDF = pd.DataFrame(data={\"text\": littleDF['text'].copy(),\n",
        "                                \"class\": littleDF['class'].copy(),\n",
        "                                \"predictedLabel\":np.nan,\n",
        "                                  \"timeRequired\":np.nan})\n",
        "elif fslDatasetChoice == \"bigDF\":\n",
        "  fslDF = pd.DataFrame(data={\"text\": bigDF['text'].copy(),\n",
        "                                \"class\": bigDF['class'].copy(),\n",
        "                                \"predictedLabel\":np.nan,\n",
        "                                  \"timeRequired\":np.nan})\n",
        "else:\n",
        "  raise ValueError(\"fslDatasetChoice must be either 'bigDF' or 'littleDF'\")"
      ],
      "metadata": {
        "id": "E9ogZJJx6Sqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset and using a smaller test set, given time required for each inference step\n",
        "fslDF, fslDiscard = train_test_split(fslDF, test_size=0.99, shuffle=True, random_state=1, stratify=fslDF['class'])"
      ],
      "metadata": {
        "id": "4zn0t9OvVlc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.3. Preparing few-shot prompts**\n",
        "In this section we construct the examples that will be fed to the model at inference time."
      ],
      "metadata": {
        "id": "ChIgTeeBjQTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the two words (i.e. labels) that we will insist our classifier chooses from (i.e. constrained text generation).\n",
        "force_words = [\"true\",\"false\"]\n",
        "# Tokenize the force words.\n",
        "force_words_ids = tokenizer(force_words, add_special_tokens=False).input_ids\n",
        "# We will set max_new_tokens / min_length to be equal to the longest / shortest force word.\n",
        "# This means that the model is prevented from generating too many or too few tokens.\n",
        "max_new_tokens = max(len(elem) for elem in force_words_ids)\n",
        "min_length = min(len(elem) for elem in force_words_ids)"
      ],
      "metadata": {
        "id": "SM8O2NPck-sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating 6 examples to guide inference.\n",
        "promptHead = \"\"\"\n",
        "####\n",
        "Statement: Monkeypox spreads through close contact with an infected person or an infected surface.\n",
        "This statement is true\n",
        "####\n",
        "Statement: Monkeypox is the government's evil plan for election fraud and more lockdowns.\n",
        "This statement is false\n",
        "####\n",
        "Statement: The city reported 56 confirmed new cases of Monkeypox - an increase of 40%.\n",
        "This statement is true\n",
        "####\n",
        "Statement: Monkeypox was created in a Wuhan laboratory and released deliberately by China.\n",
        "This statement is false\n",
        "####\n",
        "Statement: Health officials say that the first case of Monkeypox has been detected in the country.\n",
        "This statement is true\n",
        "####\n",
        "Statement: Monkeypox only affects gays because it is a sexually transmitted disease.\n",
        "This statement is false\n",
        "####\n",
        "Statement: \"\"\""
      ],
      "metadata": {
        "id": "3wbH5K_l_8mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating string to append to the prompt. (We alter string conditionally to correct \n",
        "# for erratic text generation behaviour observed during experimentation.)\n",
        "if max_new_tokens > 1:\n",
        "  promptTail = \"\"\"This statement is \"\"\"\n",
        "else:\n",
        "  promptTail = \"\"\"This statement is\"\"\""
      ],
      "metadata": {
        "id": "0qKKHFfcz65e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.4. Calling model and storing predictions**"
      ],
      "metadata": {
        "id": "tLK2odiwjb6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each tweet in our dataset ...\n",
        "for i in range(len(fslDF.index)):\n",
        "  # Time each step.\n",
        "  start = time.time()\n",
        "  # Run the text generator and compel it to produce one of the two force words.\n",
        "  sequence = fslDF['text'].iloc[i]\n",
        "  prompt = promptHead+sequence+\"\\n\"+promptTail\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "  generated_ids = fslModel.generate(input_ids, do_sample=False, max_new_tokens=max_new_tokens, min_length=min_length, num_beams=2, length_penalty=0.0,remove_invalid_values=True, force_words_ids=force_words_ids)\n",
        "  generated_text = tokenizer.decode(generated_ids[0],skip_special_tokens=True)\n",
        "  newText = generated_text.split()[-1]\n",
        "  # Add model prediction to dataframe.\n",
        "  if newText == force_words[1]:\n",
        "    fslDF.loc[fslDF.index[i], 'predictedLabel'] = 1\n",
        "  elif newText == force_words[0]:\n",
        "    fslDF.loc[fslDF.index[i], 'predictedLabel'] = 0\n",
        "  # Contingency in case model fails to output expected value.\n",
        "  else:\n",
        "    fslDF.loc[fslDF.index[i], 'predictedLabel'] = 9\n",
        "  end = time.time()\n",
        "  # Record time per step.\n",
        "  fslDF.loc[fslDF.index[i], 'timeRequired'] = end-start\n"
      ],
      "metadata": {
        "id": "XIoadQ3tul3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.5. Analysis of results**"
      ],
      "metadata": {
        "id": "ebvl9H4pjirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recasting unwanted float values as int.\n",
        "fslDF['predictedLabel'].astype('int', copy=False, errors='raise')"
      ],
      "metadata": {
        "id": "7hQIbZFeyo1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a confusion matrix based on model predictions.\n",
        "confusionMatrix = confusion_matrix(fslDF['class'], fslDF['predictedLabel'], labels=None, sample_weight=None, normalize=None)"
      ],
      "metadata": {
        "id": "pHBYRcS9Tb4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix.\n",
        "sns.heatmap(confusionMatrix, square=True, annot=True, cbar=False, cmap=\"Blues\",fmt='g')\n",
        "plt.title(\"Few-shot learning performance\")\n",
        "plt.xlabel('predicted value')\n",
        "plt.ylabel('true value')\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "696RYlNvy16r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating classification report based on model predictions.\n",
        "classificationReport = classification_report(fslDF['class'],fslDF['predictedLabel'],digits=5)"
      ],
      "metadata": {
        "id": "rxyMwpxT3_TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing classification report.\n",
        "print(classificationReport)"
      ],
      "metadata": {
        "id": "_SyNoZo84X0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5.6. Exporting experimental data**"
      ],
      "metadata": {
        "id": "GV8BIe0ojqqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting data to an Excel sheet.\n",
        "fslDF.to_excel('fslResults.xlsx', sheet_name='data')"
      ],
      "metadata": {
        "id": "Ur3Vq2irENrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding classification report to Excel workbook.\n",
        "classificationReportForPrint = classification_report(fslDF['class'],fslDF['predictedLabel'],digits=5,output_dict=True)\n",
        "classificationReportDF = pd.DataFrame(classificationReportForPrint).transpose()\n",
        "classificationReportExport = classificationReportDF.to_excel('classReportFSL.xlsx')\n",
        "# Loading Excel workbooks.\n",
        "wb = load_workbook(filename = 'fslResults.xlsx')\n",
        "wbCR = load_workbook(filename = 'classReportFSL.xlsx')\n",
        "# Creating new worksheet which is a copy of classification report.\n",
        "ws1 = wb.create_sheet(title=\"class. report\")\n",
        "ws2 = wbCR.active\n",
        "for row in ws2:\n",
        "    for cell in row:\n",
        "        ws1[cell.coordinate].value = cell.value\n",
        "# Saving changes.\n",
        "wb.save(filename = 'fslResults.xlsx')"
      ],
      "metadata": {
        "id": "I4fIwn9p5JEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding metadata to Excel sheet.\n",
        "wb = load_workbook(filename = 'fslResults.xlsx')\n",
        "ws = wb.create_sheet(title=\"metadata\")\n",
        "ws['A1'] = \"Date\"\n",
        "ws['B1'] = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
        "ws['A3'] = \"Prompts used\"\n",
        "ws['B3'] = promptHead\n",
        "ws['A5'] = \"Model used\"\n",
        "ws['B5'] = fslModelChoice\n",
        "ws['A7'] = \"Dataset used\"\n",
        "ws['B7'] = fslDatasetChoice\n",
        "ws['A9'] = \"Labels used\"\n",
        "ws['B9'] = force_words[0]+','+force_words[1]\n",
        "wb.save(filename = 'fslResults.xlsx')"
      ],
      "metadata": {
        "id": "0oWS2OViE3LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading results file.\n",
        "os.rename(\"fslResults.xlsx\",\"fsl-{}-{}-{}-{}.xlsx\".format(force_words[0],fslDatasetChoice,datetime.datetime.now().month,datetime.datetime.now().day))\n",
        "files.download(\"fsl-{}-{}-{}-{}.xlsx\".format(force_words[0],fslDatasetChoice,datetime.datetime.now().month,datetime.datetime.now().day))"
      ],
      "metadata": {
        "id": "p6y3jJrOEgHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "hBukSJbOa1c-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhjs5-KbHgOL"
      },
      "source": [
        "---\n",
        "## **6. Preprocessing the data for fine-tuning experiments**\n",
        "\n",
        "---\n",
        "For experiments using the fine-tuning approach, we will create some additional features to experiment with. We then need to pick which version of the dataset to use; select which features we want to add to the model; tokenize the text; and split the dataset into stratified training, validation and test sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**6.1. Engineering new features**\n",
        "There is a question as to whether we might be able to engineer new features to help separate the classes, particularly given suggestions that transformer models can understand numbers [(Wallace et al., 2019)](https://arxiv.org/abs/1909.07940). For example, we might add a column (as we do below) that counts the **number of years since account creation** (rather than simply listing the date on which it was created), as otherwise the model may associate misinformation with accounts created in 2022 rather than accounts that have been created recently."
      ],
      "metadata": {
        "id": "j7iRMIeImSy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a feature based on the number of years since account was created.\n",
        "for ds in [bigDF, littleDF]:\n",
        "  ds['years since account created'] = ds['created_at'].dt.year.astype('Int64') - ds['user created at'].dt.year.astype('Int64')"
      ],
      "metadata": {
        "id": "d90i5m2ep8dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We might also add a feature to identify 'spammy' accounts by dividing the total number of **tweets published by the account** by the number of days since it was created. However, we observe below no obvious difference, in this regard, between the 'misinformation' and 'other' class."
      ],
      "metadata": {
        "id": "JtwfPX5OuY6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a feature to capture tweets published per day.\n",
        "for ds in [bigDF, littleDF]:\n",
        "  ds['tweets per day'] = ds['tweet count']/((ds['created_at'] - ds['user created at']).dt.days + 1)"
      ],
      "metadata": {
        "id": "wLuxqXbgyaHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots of tweet published per day, according to class.\n",
        "sns.displot(data=bigDF,x='tweets per day',kind='hist',col='class',binrange=(0,100),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "N9DPcrdIpMj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of boxplots of tweets published per day, according to class.\n",
        "sns.boxplot(data=bigDF, x='class',y='tweets per day', showfliers=False)"
      ],
      "metadata": {
        "id": "fWtRdOP3AZws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, following suggestions in other studies, we can **divide the number of followers for each user by the number of accounts that the user follows**, based on the observation that users that follow many accounts but have few followers are more likely to be bots or trolls. (Conversely, users with many followers relative to accounts followed are intuitively more likely to be institutional accounts.) "
      ],
      "metadata": {
        "id": "5598oPXR7r8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature capturing the user's following-to-followers ratio.\n",
        "for ds in [bigDF, littleDF]:\n",
        "  ds['follower to following ratio'] = ds['followers count']/(ds['following count']+1)"
      ],
      "metadata": {
        "id": "pLhqPO488MRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of histogram plots of users' following-to-followers ratio, according to class.\n",
        "sns.displot(data=bigDF,x='follower to following ratio',kind='hist',col='class',binrange=(0,20),stat='percent',common_norm=False)"
      ],
      "metadata": {
        "id": "1wQc4vSx9bFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a series of boxplots of users' following-to-followers ratio, according to class.\n",
        "sns.boxplot(data=bigDF, x='class',y='follower to following ratio', showfliers=False)"
      ],
      "metadata": {
        "id": "wbWk8gfr-1ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format our new variables to make them more amenable to processing by a transformer model (i.e. without too many decimal points).\n",
        "bigDF['tweets per day'] = bigDF['tweets per day'].round().astype(int)\n",
        "bigDF['follower to following ratio'] = bigDF['follower to following ratio'].round(decimals=1)"
      ],
      "metadata": {
        "id": "i4oG5Ud-PEfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8PuJUdnGpuX"
      },
      "source": [
        "###**6.2. Selecting dataset version**\n",
        "For fine-tuning experiments, we will focus on the larger of the two dataset options, as this represents a greater challenge and is arguably more representative of the real-world demands that a classifier would be confronted with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGEhm2nt_ldm"
      },
      "outputs": [],
      "source": [
        "# datasetChoice must either be bigDF or littleDF\n",
        "datasetChoice = bigDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**6.3. Selecting features**\n",
        "We have the following features to choose from, in terms of model inputs."
      ],
      "metadata": {
        "id": "vQlSWgB_F5a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cols in datasetChoice.columns:\n",
        "    print(cols)"
      ],
      "metadata": {
        "id": "lx4fQqSmY0Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excluding the class label (which must be selected), we will select the following features as inputs to the model."
      ],
      "metadata": {
        "id": "lrZK40zBZ1El"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify features to select.\n",
        "chosenFeatures = ['text', 'user is verified', 'class']\n",
        "# Concatenated features will be the selected features minus the class label.\n",
        "featuresToConcatenate = chosenFeatures.copy()\n",
        "featuresToConcatenate.remove('class')"
      ],
      "metadata": {
        "id": "NAOjFhT6Zy7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the desired features in a copy of the dataframe.\n",
        "if datasetChoice is bigDF:\n",
        "  recordedDSChoice = 'Misinformation / other'\n",
        "  slimmedDownDF = datasetChoice[chosenFeatures].copy()\n",
        "  for i in featuresToConcatenate:\n",
        "    slimmedDownDF[i] = slimmedDownDF[i].name + \": \" + slimmedDownDF[i].astype(str)\n",
        "  slimmedDownDF['combined'] = slimmedDownDF[featuresToConcatenate].apply(lambda row: ' [SEP] '.join(row.values.astype(str)), axis=1)\n",
        "  finalDF = slimmedDownDF[['combined','class']].copy()\n",
        "  classNames = [\"other\",\"misinformation\"]\n",
        "elif datasetChoice is littleDF:\n",
        "  recordedDSChoice = 'Misinformation / good'\n",
        "  slimmedDownDF = datasetChoice[chosenFeatures].copy()\n",
        "  for i in featuresToConcatenate:\n",
        "    slimmedDownDF[i] = slimmedDownDF[i].name + \": \" + slimmedDownDF[i].astype(str)\n",
        "  slimmedDownDF['combined'] = slimmedDownDF[featuresToConcatenate].apply(lambda row: ' [SEP] '.join(row.values.astype(str)), axis=1)\n",
        "  finalDF = slimmedDownDF[['combined','class']].copy()\n",
        "  classNames = [\"good information\",\"misinformation\"]\n",
        "else:\n",
        "  raise ValueError(\"datasetChoice must be either 'bigDF' or 'littleDF'\")\n",
        "# Create a Huggingface dataset object from the slimmed-down Pandas dataframe.\n",
        "ds_features = Features({'combined': Value('string'), 'class': ClassLabel(names=classNames)})\n",
        "dataset = Dataset.from_pandas(df=finalDF, features=ds_features,preserve_index=False)"
      ],
      "metadata": {
        "id": "w0MwqIJeKfGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a few examples from the concatenated dataframe, to make sure everything has gone to plan.\n",
        "y=1\n",
        "for x in finalDF['combined']:\n",
        "  print(\"******************************************************\")\n",
        "  print(y)\n",
        "  print(x)\n",
        "  y+=1\n",
        "  if y==10:\n",
        "    break"
      ],
      "metadata": {
        "id": "aaHxpvt2NffQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx1RBIt5Gw9p"
      },
      "source": [
        "###**6.4. Tokenizing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waDl9NiATWft"
      },
      "outputs": [],
      "source": [
        "# Specify at this stage which model we wish to use and use this ID as input to the tokenizer.\n",
        "ftModelChoice = \"digitalepidemiologylab/covid-twitter-bert-v2\"\n",
        "# Note: this doesn't work for covid-twitter-bert-v2 -- hence why we stipulate a different tokenizer!\n",
        "if ftModelChoice == \"digitalepidemiologylab/covid-twitter-bert-v2\":\n",
        "   tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\", use_fast=True)\n",
        "else:\n",
        "  # Use fast tokenizer if available for model; otherwise, use a slow tokenizer.\n",
        "  try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=ftModelChoice, use_fast=True)\n",
        "  except:\n",
        "    try:\n",
        "      tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=ftModelChoice,use_fast=False)\n",
        "    except:\n",
        "      raise ValueError(\"An error occurred in instantiating the tokenizer.\")\n",
        "\n",
        "# Tokenize the dataset.\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples['combined'], padding = \"max_length\", truncation=True)\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVN5EEKG4XF"
      },
      "source": [
        "###**6.5. Exporting initial embeddings**\n",
        "We can optionally export the initial embeddings as TSV files to visualise using Tensorboard's embedding projector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SH5U2MTNbMU"
      },
      "outputs": [],
      "source": [
        "exportInitialEmbeddings = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suDJlK2IJEAO"
      },
      "outputs": [],
      "source": [
        "if exportInitialEmbeddings == True:\n",
        "  # Convert from HuggingFace to TF dataset format.\n",
        "  tfTokenizedDataset = tokenized_datasets.to_tf_dataset(\n",
        "      columns=[\"input_ids\",\"class\"],\n",
        "      shuffle=False,\n",
        "      batch_size=1)\n",
        "  # Convert from TF dataset to Pandas dataframe.\n",
        "  pdTokenizedDataset = tfds.as_dataframe(tfTokenizedDataset)\n",
        "  # Split into two files required for the embedding projector.\n",
        "  vectors = pd.DataFrame(pdTokenizedDataset['input_ids'])\n",
        "  metadata = pd.DataFrame(pdTokenizedDataset[\"class\"])\n",
        "  # Remove outer list wrappings and export to tsv file.\n",
        "  fileNo = 1\n",
        "  for series in [vectors['input_ids'], metadata[\"class\"]]:\n",
        "    unwrappedData = []\n",
        "    for index, value in series.items():\n",
        "      for vector in value:\n",
        "        unwrappedData.append(vector)\n",
        "    pdUnwrapped = pd.DataFrame(unwrappedData)\n",
        "    pdUnwrapped.to_csv('{}.tsv'.format(fileNo), header=False,index=False,sep='\\t')\n",
        "    fileNo += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw4sBidiNiUD"
      },
      "source": [
        "###**6.6. Splitting the dataset**\n",
        "We next split the dataset into training, validation and test sets in TensorFlow data formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXqbejyD-qds"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset into training and test/val sets.\n",
        "trainSize = 0.7\n",
        "valTestSize = 1 - trainSize\n",
        "train_testvalid = tokenized_datasets.train_test_split(test_size=valTestSize,stratify_by_column='class',seed=5)\n",
        "# Splitting test/val set into equally sized validation and test sets.\n",
        "valid_test = train_testvalid['test'].train_test_split(test_size=0.5,stratify_by_column='class',seed=5)\n",
        "# Renaming test and val sets for convenience.\n",
        "val_set = valid_test['train']\n",
        "test_set = valid_test['test']\n",
        "# Optionally, discard some training data to see how performance is affected during model fitting.\n",
        "percentToDiscard = 0\n",
        "if percentToDiscard != 0:\n",
        "  trainSize = trainSize * (1-percentToDiscard)\n",
        "  train_split = train_testvalid['train'].train_test_split(test_size=percentToDiscard,stratify_by_column='class',seed=5)\n",
        "  train_set = train_split['train']\n",
        "else:\n",
        "  train_set = train_testvalid['train']\n",
        "percentageKept = trainSize + valTestSize\n",
        "samplesUsed = len(train_set['class']) + len(val_set['class']) + len(test_set['class']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnMKvbu786f7"
      },
      "outputs": [],
      "source": [
        "# Specify batch size to be used.\n",
        "batch_size = 4\n",
        "# Converting the tokenized datasets to TensorFlow datasets.\n",
        "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
        "tf_train_dataset = train_set.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=['class'],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "tf_validation_dataset = val_set.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=['class'],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "tf_test_dataset = test_set.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
        "    label_cols=['class'],\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPpfiXubdfDq"
      },
      "source": [
        "<br>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U77kLZn1JHY3"
      },
      "source": [
        "---\n",
        "## **7. Fine-tuning the model**\n",
        "\n",
        "---\n",
        "We can now use TensorFlow to fine-tune our selected model using the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.1. Instantiating and compiling the model**"
      ],
      "metadata": {
        "id": "T3_ACb68msJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating the model.\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(ftModelChoice, num_labels=2)"
      ],
      "metadata": {
        "id": "yg-9b-zsFL37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create schedule for learning rate decay.\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-6,decay_steps=10000,decay_rate=0.8)\n",
        "# Decide at this point whether learning rate should decay (\"decay\") OR reduce on plateau (\"plateau\").\n",
        "learningRateStrategy = \"plateau\""
      ],
      "metadata": {
        "id": "sGmWXSz3w6ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "if learningRateStrategy == \"decay\":\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "elif learningRateStrategy == \"plateau\":\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
      ],
      "metadata": {
        "id": "80-1sBJfSaOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBz6Uv4MBBAp"
      },
      "outputs": [],
      "source": [
        "# Print summary of model structure.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For covid-twitter-bert: the default dropout rate for the dropout layer near the model head is 0.1.\n",
        "# The following line can be used to alter the dropout rate for this layer.\n",
        "if ftModelChoice == \"digitalepidemiologylab/covid-twitter-bert-v2\":\n",
        "  dropoutRate = 0.2\n",
        "  model.get_layer('dropout_73').rate = dropoutRate"
      ],
      "metadata": {
        "id": "ERBGY5KtTtkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.2. Creating custom callbacks**\n",
        "To optimise model performance and ensure that we collect the data we need, we will use a series of callbacks."
      ],
      "metadata": {
        "id": "3I7MNfzany1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding an early stopping callback that will restore weights with the lowest val loss.\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True)"
      ],
      "metadata": {
        "id": "xqG3ipYliADW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If learning rate strategy is to use reduce-on-plateau, use a callback to reduce the learning rate when no improvement is observed after two epochs.\n",
        "reduceLRonPlateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=2, verbose=1)"
      ],
      "metadata": {
        "id": "VpDwquS3mb4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating custom callback for training time per epoch.\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "metadata": {
        "id": "hMpe8Zy7Fj6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating custom training-time callback.\n",
        "time_callback = TimeHistory()"
      ],
      "metadata": {
        "id": "oNdj_A8lF_CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.3. Fitting the model**"
      ],
      "metadata": {
        "id": "rekDJSdVoEb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before fitting, creating serial number that we can use to differentiate between experiments using the same params.\n",
        "now = datetime.datetime.now()\n",
        "year = str(now.year)\n",
        "month = str(now.month)\n",
        "day = str(now.day)\n",
        "hour = str(now.hour)\n",
        "minute = str(now.minute)\n",
        "now = [year,month,day,hour,minute]\n",
        "serialNo = \"\"\n",
        "for i in now:\n",
        "  if len(i) == 1:\n",
        "    i = '0'+i\n",
        "  serialNo += i\n",
        "serialNo = int(serialNo)"
      ],
      "metadata": {
        "id": "c21c5NdMHzhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGy1UFdLKc5U"
      },
      "outputs": [],
      "source": [
        "# Fitting model either with learning rate plateau strategy or decay strategy.\n",
        "if learningRateStrategy == \"decay\":\n",
        "  history = model.fit(tf_train_dataset,\n",
        "            validation_data=tf_validation_dataset,\n",
        "            epochs=50,\n",
        "            callbacks=[early_stopping_callback, time_callback])\n",
        "elif learningRateStrategy == \"plateau\":\n",
        "  history = model.fit(tf_train_dataset,\n",
        "            validation_data=tf_validation_dataset,\n",
        "            epochs=50,\n",
        "            callbacks=[early_stopping_callback,reduceLRonPlateau,time_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.4. Saving training data**"
      ],
      "metadata": {
        "id": "w46B0JcwpnEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataframe to store results of model training.\n",
        "histDF = pd.DataFrame(history.history)\n",
        "histDF['time_per_epoch'] =  time_callback.times\n",
        "histDF['datasetChoice'] = recordedDSChoice\n",
        "histDF['percentageKept'] = percentageKept\n",
        "histDF['samplesUsed'] = samplesUsed\n",
        "histDF['trainSize'] = trainSize\n",
        "histDF['valSize'] = valTestSize / 2\n",
        "histDF['testSize'] = valTestSize / 2\n",
        "histDF['model'] = ftModelChoice\n",
        "histDF['batchSize'] = batch_size\n",
        "histDF['LRstrategy'] = learningRateStrategy\n",
        "histDF['dropoutRate'] = dropoutRate\n",
        "allDatasetCols = [col for col in datasetChoice]\n",
        "allDatasetCols.remove('class')\n",
        "histDF[[allDatasetCols]] = False\n",
        "for i in chosenFeatures:\n",
        "  if i in histDF.columns:\n",
        "    histDF[i] = True\n",
        "histDF['isFastTokenizer'] = tokenizer.is_fast\n",
        "histDF['optimizer'] = model.optimizer.get_config()['name']\n",
        "histDF['serialNumber'] = serialNo"
      ],
      "metadata": {
        "id": "W1dfevH4-NIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting training data to an Excel sheet.\n",
        "histDF.to_excel('finetuneResults.xlsx')"
      ],
      "metadata": {
        "id": "BNhrNvQhqIWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.5. Evaluating the fine-tuned model on test data**\n",
        "\n"
      ],
      "metadata": {
        "id": "m9_gnjpLsOgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating classification report based on model predictions.\n",
        "testDataLabels = np.concatenate([y for x, y in tf_test_dataset], axis=0)\n",
        "modelLogits = model.predict(tf_test_dataset).logits\n",
        "modelPredictions = []\n",
        "for i in range(len(modelLogits)):\n",
        "  prediction = np.argmax(modelLogits[i])\n",
        "  modelPredictions.append(prediction)\n",
        "classificationReport = classification_report(testDataLabels,modelPredictions,digits=5)\n",
        "print(classificationReport)"
      ],
      "metadata": {
        "id": "89Du83201M7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and plotting a confusion matrix based on model predictions.\n",
        "confusionMatrix = confusion_matrix(testDataLabels, modelPredictions, labels=None, sample_weight=None, normalize=None)\n",
        "sns.heatmap(confusionMatrix, square=True, annot=True, cbar=False, cmap=\"Blues\",fmt='g')\n",
        "plt.title(\"Fine-tuned model predictions\")\n",
        "plt.xlabel('predicted value')\n",
        "plt.ylabel('true value')\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "_4d28Rlj19vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding classification report to Excel workbook.\n",
        "classificationReportForPrint = classification_report(testDataLabels,modelPredictions,digits=5,output_dict=True)\n",
        "classificationReportDF = pd.DataFrame(classificationReportForPrint).transpose()\n",
        "classificationReportExport = classificationReportDF.to_excel('classReportFT.xlsx')\n",
        "# Loading Excel workbooks.\n",
        "wb = load_workbook(filename = 'finetuneResults.xlsx')\n",
        "wbCR = load_workbook(filename = 'classReportFT.xlsx')\n",
        "# Creating new worksheet which is a copy of classification report.\n",
        "ws1 = wb.create_sheet(title=\"class. report\")\n",
        "ws2 = wbCR.active\n",
        "for row in ws2:\n",
        "    for cell in row:\n",
        "        ws1[cell.coordinate].value = cell.value\n",
        "# Saving changes.\n",
        "wb.save(filename = 'finetuneResults.xlsx')"
      ],
      "metadata": {
        "id": "We2nD5G9Ygnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**7.6. Exporting experimental data**"
      ],
      "metadata": {
        "id": "w1xbFLqfKyW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export fine-tuning data\n",
        "if ftModelChoice == \"digitalepidemiologylab/covid-twitter-bert-v2\":\n",
        "  os.rename(\"finetuneResults.xlsx\",\"finetuneResults-covid-twitter-bert-{}-{}.xlsx\".format(datetime.datetime.now().month,datetime.datetime.now().day))\n",
        "  files.download(\"finetuneResults-covid-twitter-bert-{}-{}.xlsx\".format(datetime.datetime.now().month,datetime.datetime.now().day))\n",
        "else:\n",
        "  os.rename(\"finetuneResults.xlsx\",\"finetuneResults-{}-{}-{}.xlsx\".format(ftModelChoice,datetime.datetime.now().month,datetime.datetime.now().day))\n",
        "  files.download(\"finetuneResults-{}-{}-{}.xlsx\".format(ftModelChoice,datetime.datetime.now().month,datetime.datetime.now().day))"
      ],
      "metadata": {
        "id": "QmKqrkXZY5m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Saving and exporting best model**\n",
        "For the model evaluated as 'best in class', we can push the model to the HuggingFace model hub."
      ],
      "metadata": {
        "id": "CwfkN95Xsrqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notebook_login()"
      ],
      "metadata": {
        "id": "zV_AKwPm7MH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.push_to_hub(\"monkeypox-misinformation\")\n",
        "# tokenizer.push_to_hub(\"monkeypox-misinformation\")"
      ],
      "metadata": {
        "id": "u76gLo0L49th"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOmBZeEY6jZD60yaa235jzh",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
